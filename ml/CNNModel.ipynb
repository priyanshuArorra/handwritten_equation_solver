{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aruls\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "import torch  # Import PyTorch for tensor operations\n",
    "import dask.dataframe as dd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import get_scheduler\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aruls\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_train = dd.read_csv('model/train_data.csv', assume_missing=True).compute()\n",
    "\n",
    "# Set the number of samples to read from each class (adjust this as needed)\n",
    "samples_per_class = 100  # Modify this number based on your memory constraints\n",
    "\n",
    "# Create a new DataFrame to hold the sampled data\n",
    "sampled_data = []\n",
    "\n",
    "# Loop through each class and sample the specified number of images\n",
    "for label in df_train['784'].unique():\n",
    "    class_data = df_train[df_train['784'] == label].sample(n=min(samples_per_class, len(df_train[df_train['784'] == label])), random_state=42)\n",
    "    sampled_data.append(class_data)\n",
    "\n",
    "# Concatenate all the sampled data into a single DataFrame\n",
    "sampled_df = pd.concat(sampled_data)\n",
    "\n",
    "# Separate labels and features\n",
    "labels = sampled_df[['784']].values  # Extract labels as a NumPy array\n",
    "sampled_df.drop(columns=['784'], inplace=True)  # Drop the label column from features\n",
    "\n",
    "# One-hot encode the labels for classification (17 classes)\n",
    "categorical_data = to_categorical(labels, num_classes=17)\n",
    "\n",
    "# Reshape the training data to 28x28x1 (grayscale) and convert to RGB (3 channels)\n",
    "l = []\n",
    "for i in range(sampled_df.shape[0]):\n",
    "    # Reshape to (28, 28, 1) and then convert to (28, 28, 3) for RGB\n",
    "    image = sampled_df.iloc[i].values.reshape(28, 28, 1)\n",
    "    image_rgb = np.concatenate((image, image, image), axis=-1)  # Convert to 3 channels\n",
    "    l.append(image_rgb)\n",
    "\n",
    "# Convert list to NumPy array for further processing\n",
    "l = np.array(l)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(l, categorical_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess images for Vision Transformer\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# Extract features from images\n",
    "train_features = [feature_extractor(image, return_tensors=\"pt\")[\"pixel_values\"] for image in train_X]\n",
    "test_features = [feature_extractor(image, return_tensors=\"pt\")[\"pixel_values\"] for image in test_X]\n",
    "\n",
    "# Convert feature lists to PyTorch tensors\n",
    "train_features = torch.cat(train_features)  # Combine the list of tensors into a single tensor\n",
    "test_features = torch.cat(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor([np.argmax(y) for y in train_y])\n",
    "test_labels = torch.tensor([np.argmax(y) for y in test_y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "train_data = TensorDataset(train_features, train_labels)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Prepare DataLoader for testing\n",
    "test_data = TensorDataset(test_features, test_labels)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)  # No shuffling for test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k',\n",
    "    num_labels=17  # We have 17 classes (digits + symbols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer, loss function, and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)  # Use AdamW instead of Adam\n",
    "criterion = CrossEntropyLoss()\n",
    "num_epochs = 5\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_epochs * len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2.1576, Time: 818.36 seconds\n",
      "Epoch 2/5, Loss: 1.1452, Time: 812.30 seconds\n",
      "Epoch 3/5, Loss: 0.7534, Time: 810.67 seconds\n",
      "Epoch 4/5, Loss: 0.5864, Time: 836.26 seconds\n",
      "Epoch 5/5, Loss: 0.5101, Time: 810.65 seconds\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    start_time = time.time()  # Record the start time of the epoch\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        outputs = model(inputs).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    end_time = time.time()  # Record the end time of the epoch\n",
    "    epoch_time = end_time - start_time  # Calculate the duration of the epoch\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}, Time: {epoch_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('model/vit_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
